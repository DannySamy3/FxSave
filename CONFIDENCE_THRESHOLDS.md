# Trading Confidence Thresholds - Optimized Based on Model Accuracy

## Model Performance (Jan 5, 2026)

| Timeframe | Test Accuracy | Recommendation | Signal Status |
|-----------|--------------|-----------------|--------------|
| **1d**    | 55.24%       | âœ… Trade        | Best |
| **30m**   | 53.82%       | âœ… Trade        | Good |
| **4h**    | 50.95%       | âš ï¸ Moderate     | Fair |
| **15m**   | 51.57%       | âš ï¸ Moderate     | Fair |
| **1h**    | 46.87%       | âŒ Block        | Unreliable |

---

## Confidence Thresholds (Updated)

Your app now uses **timeframe-specific confidence gates** that match model performance:

### Minimum Confidence Required for Trades

```json
{
  "15m": 52%,    // 51.57% accuracy â†’ require 52% confidence
  "30m": 54%,    // 53.82% accuracy â†’ require 54% confidence
  "1h":  60%,    // 46.87% accuracy â†’ require 60% (blocks most signals)
  "4h":  53%,    // 50.95% accuracy â†’ require 53% confidence
  "1d":  55%     // 55.24% accuracy â†’ require 55% confidence
}
```

### Minimum Risk Management Threshold

```
Global minimum: 52% (base threshold)
High confidence: 60% (considered strong signal)
```

---

## Signal Generation Rules

### ðŸŸ¢ WILL TRADE (Green Light)

- **1d**: Confidence â‰¥ 55% 
- **30m**: Confidence â‰¥ 54%
- **4h**: Confidence â‰¥ 53%
- **15m**: Confidence â‰¥ 52%

### ðŸŸ¡ REVIEW SIGNAL (Yellow Light)

- **1h**: Confidence â‰¥ 60% (very rare, model is poor)
- Calibration drift > 15% â†’ risk reduction activated
- HTF conflict detected â†’ risk cut by 50%

### ðŸ”´ NO TRADE (Red Light)

- Confidence below thresholds
- 1h timeframe confidence < 60%
- High-impact news event
- Market regime = RANGE
- Calibration drift > 25% (critical)

---

## How This Works in Practice

### Example 1: 30m Signal
```
Model predicts: UP with 55% confidence
Check: 55% > 54% threshold âœ…
Result: TRADE with 100% risk allocation
```

### Example 2: 1h Signal  
```
Model predicts: UP with 58% confidence
Check: 58% < 60% threshold âŒ
Result: NO_TRADE - confidence too low
```

### Example 3: 1d Signal
```
Model predicts: DOWN with 56% confidence
Check: 56% > 55% threshold âœ…
Result: TRADE with 100% risk allocation
```

---

## Implementation Details

**Files Updated:**
- `config.json` - Added `min_confidence_by_timeframe`
- `rules_engine.py` - Now checks timeframe-specific thresholds

**Signal Flow:**
1. Model generates probability prediction
2. Calibration adjusts probability (improves accuracy)
3. Rules engine checks confidence vs. timeframe threshold
4. If confidence too low â†’ `NO_TRADE` with `LOW_CONFIDENCE` code
5. If passes â†’ Continue to other checks (HTF alignment, regime, news, etc.)

---

## Expected Live Performance

With these thresholds, you should expect:
- **~51-55% Win Rate** on actual trades (matching backtest)
- **Lower false signals** (only trade high-confidence setups)
- **Better risk/reward** (fewer mediocre trades)
- **1h timeframe blocked** for most signals (unreliable model)

---

## Note on Probability Calibration

Your calibrator now:
- Adjusts raw model probabilities to match actual accuracy
- Improves Brier score by 0.3-2% on each timeframe
- Reduces overfitting bias (57% prob â†’ 54% prob, etc.)

This means **your calibrated confidence is already reality-adjusted** - when it says 54%, that's approximately the real-world accuracy.

